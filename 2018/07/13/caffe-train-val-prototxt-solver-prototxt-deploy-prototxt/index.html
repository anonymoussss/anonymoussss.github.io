<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>caffe:train_val.prototxt,solver.prototxt,deploy.prototxt | anonymous sss</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="caffe中train_val.prototxt和deploy.prototxt文件的区别 以LeNet网络结构为例子,这两个文件不同点主要在一前一后，中间是相同的  ###train_val.prototxt 中的开头  里面定义的是训练和验证时候的网络，所以在开始的时候要定义训练集和验证集的来源  123456789101112131415161718192021222324252627282">
<meta name="keywords" content="caffe,deep learning,CV">
<meta property="og:type" content="article">
<meta property="og:title" content="caffe:train_val.prototxt,solver.prototxt,deploy.prototxt">
<meta property="og:url" content="http://yoursite.com/2018/07/13/caffe-train-val-prototxt-solver-prototxt-deploy-prototxt/index.html">
<meta property="og:site_name" content="anonymous sss">
<meta property="og:description" content="caffe中train_val.prototxt和deploy.prototxt文件的区别 以LeNet网络结构为例子,这两个文件不同点主要在一前一后，中间是相同的  ###train_val.prototxt 中的开头  里面定义的是训练和验证时候的网络，所以在开始的时候要定义训练集和验证集的来源  123456789101112131415161718192021222324252627282">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-07-13T03:17:04.582Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="caffe:train_val.prototxt,solver.prototxt,deploy.prototxt">
<meta name="twitter:description" content="caffe中train_val.prototxt和deploy.prototxt文件的区别 以LeNet网络结构为例子,这两个文件不同点主要在一前一后，中间是相同的  ###train_val.prototxt 中的开头  里面定义的是训练和验证时候的网络，所以在开始的时候要定义训练集和验证集的来源  123456789101112131415161718192021222324252627282">
  
    <link rel="alternate" href="/atom.xml" title="anonymous sss" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">anonymous sss</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-caffe-train-val-prototxt-solver-prototxt-deploy-prototxt" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/13/caffe-train-val-prototxt-solver-prototxt-deploy-prototxt/" class="article-date">
  <time datetime="2018-07-13T02:38:09.000Z" itemprop="datePublished">2018-07-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      caffe:train_val.prototxt,solver.prototxt,deploy.prototxt
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="caffe中train-val-prototxt和deploy-prototxt文件的区别"><a href="#caffe中train-val-prototxt和deploy-prototxt文件的区别" class="headerlink" title="caffe中train_val.prototxt和deploy.prototxt文件的区别"></a>caffe中train_val.prototxt和deploy.prototxt文件的区别</h2><blockquote>
<p>以LeNet网络结构为例子,这两个文件不同点主要在一前一后，中间是相同的</p>
</blockquote>
<p>###train_val.prototxt 中的开头</p>
<blockquote>
<p>里面定义的是训练和验证时候的网络，所以在开始的时候要定义训练集和验证集的来源</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">name: &quot;LeNet&quot;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;mnist&quot;</span><br><span class="line">  type: &quot;Data&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  top: &quot;label&quot;</span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TRAIN</span><br><span class="line">  &#125;</span><br><span class="line">  transform_param &#123;</span><br><span class="line">    scale: 0.00390625</span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    # 这里定义了之前将数据集转成lmdb数据格式的文件位置</span><br><span class="line">    source: &quot;examples/mnist/mnist_train_lmdb&quot;</span><br><span class="line">    # 这个定义了一次行送入网络的图像个数</span><br><span class="line">    batch_size: 64</span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;mnist&quot;</span><br><span class="line">  type: &quot;Data&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  top: &quot;label&quot;</span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST</span><br><span class="line">  &#125;</span><br><span class="line">  transform_param &#123;</span><br><span class="line">    scale: 0.00390625</span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    # 这里定义了验证集的数据来源</span><br><span class="line">    source: &quot;examples/mnist/mnist_test_lmdb&quot;</span><br><span class="line">    batch_size: 100</span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>###deploy.prototxt 中的开头</p>
<blockquote>
<p>这个配置文件适用于部署，也就是用于实际场景时候的配置文件，所以开始的时候不必在定义数据集的来源，但是需要定义输入数据的大小格式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">name: &quot;LeNet&quot;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;data&quot;</span><br><span class="line">  type: &quot;Input&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  # 输入数据的batch size, channel, width, height</span><br><span class="line">  input_param &#123; shape: &#123; dim: 64 dim: 1 dim: 28 dim: 28 &#125; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>###train_val.prototxt 中的结尾</p>
<blockquote>
<p>如果是一般的卷积网络的话，最后面都是用一个全连接，将feature map 转成固定长度的向量，然后输出种类的个数。所以在最后的时候，需要说明输出种类的个数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;ip2&quot;</span><br><span class="line">  type: &quot;InnerProduct&quot;</span><br><span class="line">  bottom: &quot;ip1&quot;</span><br><span class="line">  top: &quot;ip2&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    # 在这里定义了输出种类的个数</span><br><span class="line">    num_output: 10</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;xavier&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>因为这里面包含了验证的部分，验证的时候，需要输出结果的准确率，所以需要定义准确率的输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;accuracy&quot;</span><br><span class="line">  type: &quot;Accuracy&quot;</span><br><span class="line">  bottom: &quot;ip2&quot;</span><br><span class="line">  bottom: &quot;label&quot;</span><br><span class="line">  top: &quot;accuracy&quot;</span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>最后还有一个不同就是，因为是训练模型，所以包括forward和backward，所以最后需要定义一个损失函数。这里用的是SoftmaxWithLoss，而在deploy.prototxt，因为只有forward，所以定义的是Softmax，也就是分类器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;loss&quot;</span><br><span class="line">  # 定义的是损失函数</span><br><span class="line">  type: &quot;SoftmaxWithLoss&quot;</span><br><span class="line">  bottom: &quot;ip2&quot;</span><br><span class="line">  bottom: &quot;label&quot;</span><br><span class="line">  top: &quot;loss&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>###deploy.prototxt 中的最后</p>
<blockquote>
<p>这里定义了Softmax分类器，输出最后各类的概率值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;prob&quot;</span><br><span class="line">  # 定义的是分类器</span><br><span class="line">  type: &quot;Softmax&quot;</span><br><span class="line">  bottom: &quot;ip2&quot;</span><br><span class="line">  top: &quot;prob&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>###train_val.prototxt 和 deploy.prototxt中间部分</p>
<blockquote>
<p>两个的中间部分都是一样的，定义了一些卷积、激活、池化、Dropout、LRN(local response normalization)、全连接等操作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv1&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 20</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    stride: 1</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;xavier&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;pool1&quot;</span><br><span class="line">  type: &quot;Pooling&quot;</span><br><span class="line">  bottom: &quot;conv1&quot;</span><br><span class="line">  top: &quot;pool1&quot;</span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>##solver.prototxt配置文件参数设置及含义 </p>
<blockquote>
<p>首先明确solver.prototxt的参数的含义<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">net: &quot;examples/myproject/train_val.prototxt&quot;   #训练或者测试配置文件</span><br><span class="line">test_iter: 40   #完成一次测试需要的迭代次数</span><br><span class="line">test_interval: 475  #测试间隔：每个epoch包含的iteration数量</span><br><span class="line">base_lr: 0.01  #基础学习率</span><br><span class="line">lr_policy: &quot;step&quot;  #学习率变化规律</span><br><span class="line">gamma: 0.1  #学习率变化指数</span><br><span class="line">stepsize: 9500  #学习率变化频率</span><br><span class="line">display: 20  #屏幕显示间隔</span><br><span class="line">max_iter: 47500 #最大迭代次数</span><br><span class="line">momentum: 0.9 #动量</span><br><span class="line">weight_decay: 0.0005 #权重衰减</span><br><span class="line">snapshot: 5000 #保存模型间隔</span><br><span class="line">snapshot_prefix: &quot;models/A1/caffenet_train&quot; #保存模型的前缀</span><br><span class="line">solver_mode: CPU #使用CPU还是GPU</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>这里面需要注意的就是test_iter,max_iter,test_interval,和stepsize四个参数。接下来我们做下简单地分析。</p>
<ul>
<li><strong>test_iter</strong>: 表示完成一epoch测试需要的迭代次数；比如，你的test阶段的batchsize=25，而你的测试数据为1000张图片，则测试时一个epoch中有1000/25=40个iteration</li>
<li><strong>test_interval</strong>：测试间隔：每个epoch包含的iteration数量；比如训练样本一共121368个样本，而我们训练的时候batchsize=256，可以得知一个epoch需要121368/256=475 次迭代才能完成，所以这里将test_interval设置为475，意为每训练一个epoch就进行测试。</li>
<li><strong>max_iter</strong>: 网络的最大迭代次数；如果想训练100个epoch，则最大迭代次数max_iter设置为47500。</li>
<li><strong>stepsize</strong>：学习率变化规律；我们设置该参数为随着迭代次数的增加，慢慢变低。总共迭代47500次（100个epoch），若我们想变化5次的话，stepsize设置为47500/5=9500，即每迭代9500次，我们就降低一次学习率。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/13/caffe-train-val-prototxt-solver-prototxt-deploy-prototxt/" data-id="cjjjeycg30000asuqbsbd7lil" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CV/">CV</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deep-learning/">deep learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2018/07/08/图像语义分割综述/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">图像语义分割综述</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CV/">CV</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe/">caffe</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learning/">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/semantic-segmentation/">semantic segmentation</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/caffe/" style="font-size: 10px;">caffe</a> <a href="/tags/deep-learning/" style="font-size: 20px;">deep learning</a> <a href="/tags/semantic-segmentation/" style="font-size: 10px;">semantic segmentation</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/07/13/caffe-train-val-prototxt-solver-prototxt-deploy-prototxt/">caffe:train_val.prototxt,solver.prototxt,deploy.prototxt</a>
          </li>
        
          <li>
            <a href="/2018/07/08/图像语义分割综述/">图像语义分割综述</a>
          </li>
        
          <li>
            <a href="/2018/07/07/hello-hexo/">hello_hexo!</a>
          </li>
        
          <li>
            <a href="/2018/07/07/Hexo tutorial/">Hexo tutorial</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>