<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>anonymous sss</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="anonymous sss">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="anonymous sss">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="anonymous sss">
  
    <link rel="alternate" href="/atom.xml" title="anonymous sss" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">anonymous sss</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-caffe-train-val-prototxt-solver-prototxt-deploy-prototxt" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/13/caffe-train-val-prototxt-solver-prototxt-deploy-prototxt/" class="article-date">
  <time datetime="2018-07-13T02:38:09.000Z" itemprop="datePublished">2018-07-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/13/caffe-train-val-prototxt-solver-prototxt-deploy-prototxt/">caffe:train_val.prototxt,solver.prototxt,deploy.prototxt</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="caffe中train-val-prototxt和deploy-prototxt文件的区别"><a href="#caffe中train-val-prototxt和deploy-prototxt文件的区别" class="headerlink" title="caffe中train_val.prototxt和deploy.prototxt文件的区别"></a>caffe中train_val.prototxt和deploy.prototxt文件的区别</h2><p>以LeNet网络结构为例子,这两个文件不同点主要在一前一后，中间是相同的</p>
<h3 id="train-val-prototxt-中的开头"><a href="#train-val-prototxt-中的开头" class="headerlink" title="train_val.prototxt 中的开头"></a>train_val.prototxt 中的开头</h3><p>里面定义的是训练和验证时候的网络，所以在开始的时候要定义训练集和验证集的来源</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">name: &quot;LeNet&quot;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;mnist&quot;</span><br><span class="line">  type: &quot;Data&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  top: &quot;label&quot;</span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TRAIN</span><br><span class="line">  &#125;</span><br><span class="line">  transform_param &#123;</span><br><span class="line">    scale: 0.00390625</span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    # 这里定义了之前将数据集转成lmdb数据格式的文件位置</span><br><span class="line">    source: &quot;examples/mnist/mnist_train_lmdb&quot;</span><br><span class="line">    # 这个定义了一次行送入网络的图像个数</span><br><span class="line">    batch_size: 64</span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;mnist&quot;</span><br><span class="line">  type: &quot;Data&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  top: &quot;label&quot;</span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST</span><br><span class="line">  &#125;</span><br><span class="line">  transform_param &#123;</span><br><span class="line">    scale: 0.00390625</span><br><span class="line">  &#125;</span><br><span class="line">  data_param &#123;</span><br><span class="line">    # 这里定义了验证集的数据来源</span><br><span class="line">    source: &quot;examples/mnist/mnist_test_lmdb&quot;</span><br><span class="line">    batch_size: 100</span><br><span class="line">    backend: LMDB</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="deploy-prototxt-中的开头"><a href="#deploy-prototxt-中的开头" class="headerlink" title="deploy.prototxt 中的开头"></a>deploy.prototxt 中的开头</h3><p>这个配置文件适用于部署，也就是用于实际场景时候的配置文件，所以开始的时候不必在定义数据集的来源，但是需要定义输入数据的大小格式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">name: &quot;LeNet&quot;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;data&quot;</span><br><span class="line">  type: &quot;Input&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  # 输入数据的batch size, channel, width, height</span><br><span class="line">  input_param &#123; shape: &#123; dim: 64 dim: 1 dim: 28 dim: 28 &#125; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="train-val-prototxt-中的结尾"><a href="#train-val-prototxt-中的结尾" class="headerlink" title="train_val.prototxt 中的结尾"></a>train_val.prototxt 中的结尾</h3><p>如果是一般的卷积网络的话，最后面都是用一个全连接，将feature map 转成固定长度的向量，然后输出种类的个数。所以在最后的时候，需要说明输出种类的个数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;ip2&quot;</span><br><span class="line">  type: &quot;InnerProduct&quot;</span><br><span class="line">  bottom: &quot;ip1&quot;</span><br><span class="line">  top: &quot;ip2&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    # 在这里定义了输出种类的个数</span><br><span class="line">    num_output: 10</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;xavier&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>因为这里面包含了验证的部分，验证的时候，需要输出结果的准确率，所以需要定义准确率的输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;accuracy&quot;</span><br><span class="line">  type: &quot;Accuracy&quot;</span><br><span class="line">  bottom: &quot;ip2&quot;</span><br><span class="line">  bottom: &quot;label&quot;</span><br><span class="line">  top: &quot;accuracy&quot;</span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>最后还有一个不同就是，因为是训练模型，所以包括forward和backward，所以最后需要定义一个损失函数。这里用的是SoftmaxWithLoss，而在deploy.prototxt，因为只有forward，所以定义的是Softmax，也就是分类器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;loss&quot;</span><br><span class="line">  # 定义的是损失函数</span><br><span class="line">  type: &quot;SoftmaxWithLoss&quot;</span><br><span class="line">  bottom: &quot;ip2&quot;</span><br><span class="line">  bottom: &quot;label&quot;</span><br><span class="line">  top: &quot;loss&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="deploy-prototxt-中的最后"><a href="#deploy-prototxt-中的最后" class="headerlink" title="deploy.prototxt 中的最后"></a>deploy.prototxt 中的最后</h3><p>这里定义了Softmax分类器，输出最后各类的概率值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;prob&quot;</span><br><span class="line">  # 定义的是分类器</span><br><span class="line">  type: &quot;Softmax&quot;</span><br><span class="line">  bottom: &quot;ip2&quot;</span><br><span class="line">  top: &quot;prob&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="train-val-prototxt-和-deploy-prototxt中间部分"><a href="#train-val-prototxt-和-deploy-prototxt中间部分" class="headerlink" title="train_val.prototxt 和 deploy.prototxt中间部分"></a>train_val.prototxt 和 deploy.prototxt中间部分</h3><p>两个的中间部分都是一样的，定义了一些卷积、激活、池化、Dropout、LRN(local response normalization)、全连接等操作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv1&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 20</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    stride: 1</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;xavier&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;pool1&quot;</span><br><span class="line">  type: &quot;Pooling&quot;</span><br><span class="line">  bottom: &quot;conv1&quot;</span><br><span class="line">  top: &quot;pool1&quot;</span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure></p>
<h2 id="solver-prototxt配置文件参数设置及含义"><a href="#solver-prototxt配置文件参数设置及含义" class="headerlink" title="solver.prototxt配置文件参数设置及含义"></a>solver.prototxt配置文件参数设置及含义</h2><p>首先明确solver.prototxt的参数的含义<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">net: &quot;examples/myproject/train_val.prototxt&quot;   #训练或者测试配置文件</span><br><span class="line">test_iter: 40   #完成一次测试需要的迭代次数</span><br><span class="line">test_interval: 475  #测试间隔：每个epoch包含的iteration数量</span><br><span class="line">base_lr: 0.01  #基础学习率</span><br><span class="line">lr_policy: &quot;step&quot;  #学习率变化规律</span><br><span class="line">gamma: 0.1  #学习率变化指数</span><br><span class="line">stepsize: 9500  #学习率变化频率</span><br><span class="line">display: 20  #屏幕显示间隔</span><br><span class="line">max_iter: 47500 #最大迭代次数</span><br><span class="line">momentum: 0.9 #动量</span><br><span class="line">weight_decay: 0.0005 #权重衰减</span><br><span class="line">snapshot: 5000 #保存模型间隔</span><br><span class="line">snapshot_prefix: &quot;models/A1/caffenet_train&quot; #保存模型的前缀</span><br><span class="line">solver_mode: CPU #使用CPU还是GPU</span><br></pre></td></tr></table></figure></p>
<p>这里面需要注意的就是test_iter,max_iter,test_interval,和stepsize四个参数。接下来我们做下简单地分析。</p>
<ul>
<li><strong>test_iter</strong>: 表示完成一epoch测试需要的迭代次数；比如，你的test阶段的batchsize=25，而你的测试数据为1000张图片，则测试时一个epoch中有1000/25=40个iteration</li>
<li><strong>test_interval</strong>：测试间隔：每个epoch包含的iteration数量；比如训练样本一共121368个样本，而我们训练的时候batchsize=256，可以得知一个epoch需要121368/256=475 次迭代才能完成，所以这里将test_interval设置为475，意为每训练一个epoch就进行测试。</li>
<li><strong>max_iter</strong>: 网络的最大迭代次数；如果想训练100个epoch，则最大迭代次数max_iter设置为47500。</li>
<li><strong>stepsize</strong>：学习率变化规律；我们设置该参数为随着迭代次数的增加，慢慢变低。总共迭代47500次（100个epoch），若我们想变化5次的话，stepsize设置为47500/5=9500，即每迭代9500次，我们就降低一次学习率。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/13/caffe-train-val-prototxt-solver-prototxt-deploy-prototxt/" data-id="cjjjf8q1u0001u8uqj1zklbhd" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CV/">CV</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/caffe/">caffe</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deep-learning/">deep learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-图像语义分割综述" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/08/图像语义分割综述/" class="article-date">
  <time datetime="2018-07-08T12:38:44.000Z" itemprop="datePublished">2018-07-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/08/图像语义分割综述/">图像语义分割综述</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-研究历史"><a href="#1-研究历史" class="headerlink" title="1 研究历史"></a>1 研究历史</h2><h3 id="patch-classification"><a href="#patch-classification" class="headerlink" title="patch classification"></a>patch classification</h3><p>最初的图像语义分割方法，费时费力</p>
<h3 id="FCN-2014"><a href="#FCN-2014" class="headerlink" title="FCN(2014)"></a>FCN(2014)</h3><p>FCN 使用反卷积（与upsamping的区别是可学习）取代简单的线性插值算法进行上采样</p>
<h3 id="SegNet-2015"><a href="#SegNet-2015" class="headerlink" title="SegNet (2015)"></a>SegNet (2015)</h3><p>SegNet使用upsampling的方法将编码过程中 pool 的位置记下来在 uppooling 是使用该信息进行pooling </p>
<h3 id="U-Net-2015"><a href="#U-Net-2015" class="headerlink" title="U-Net (2015)"></a>U-Net (2015)</h3><p>在前者的基础上进行的改进，将编码器的每层结果拼接到译码器中得到更好的结果</p>
<h3 id="DeepLab-v1-2015"><a href="#DeepLab-v1-2015" class="headerlink" title="DeepLab v1(2015)"></a>DeepLab v1(2015)</h3><p><strong>特点</strong>：</p>
<ul>
<li>VGG16的全连接层转为卷积</li>
<li>最后的两个池化层去掉了下采样</li>
<li>后续卷积层的卷积核改为了空洞卷积</li>
<li>在ImageNet上预训练的VGG16权重上做finetune</li>
</ul>
<p><strong>说明</strong>：<br>我们知道，池化操作在分类网络中能够扩大感知域，但同样降低了分辨率。随着15年空洞卷积（dilated convolution）的概念被提出， DeepLab 中将其称为带孔卷积 (atrous convolution) 在论文中进行了应用。通过这种卷积方式能够极大的扩大感知域同时不减小空间维度。<br>论文提出的模型移去了VGG预训练模型的最后两层池化层，并且其后续的卷积层都采用空洞卷积。<br>除此之外作者尝试在模型的最后增加条件随机场（CRF）来描述像素和像素之间的关系，如果比较相似，那可能是一类，否则就裂开，这可以细化边缘。<br>论文最后探讨了使用多尺度预测提高边界定位效果。合起来模型最后的softmax层输入特征多了640个通道，实验表示多尺度有助于提升预测结果，但是效果不如CRF明显。</p>
<h3 id="DeepLab-v2-2016"><a href="#DeepLab-v2-2016" class="headerlink" title="DeepLab v2(2016)"></a>DeepLab v2(2016)</h3><p><strong>特点</strong>：</p>
<ul>
<li>用多尺度获得更好的分割效果(使用ASPP) </li>
<li>基础层由VGG16转为ResNet </li>
<li>使用不同的学习策略(poly)</li>
</ul>
<p>在deeplab v1的论文中就有对多尺度预测效果的讨论，在deeplab v2的论文中作者提出了<strong>带孔卷积金字塔池化 (ASPP)</strong>结构，融合了不同尺度的信息。</p>
<h3 id="RefineNet（2016）"><a href="#RefineNet（2016）" class="headerlink" title="RefineNet（2016）"></a>RefineNet（2016）</h3><p><strong>特点</strong>：重新设计的译码模块，并且所有模块遵循残余连接设计<br><strong>说明</strong>：空洞卷积有几个缺点，如计算量大、需要大量内存。这篇文章采用编码-译码架构。编码部分是 ResNet-101 模块。译码则采用 RefineNet 模块，该模块融合了编码模块的高分辨率特征和前一个 RefineNet 模块的抽象特征。<br>每个 RefineNet 模块接收多个不同分辨率特征，并融合。<br><img src="/2018/07/08/图像语义分割综述/1531051570272.png" alt="RefineNet"><br><img src="/2018/07/08/图像语义分割综述/1531051603979.png" alt="RefineNet"></p>
<h3 id="PSPNet-2016"><a href="#PSPNet-2016" class="headerlink" title="PSPNet (2016)"></a>PSPNet (2016)</h3><p>Pyramid Scene Parsing Network 金字塔场景解析网络<br><strong>特点</strong>：</p>
<ul>
<li>提出了金字塔池化模块来<strong>聚合</strong>图片信息</li>
<li>使用<strong>附加的损失函数</strong>（auxiliary loss）。</li>
</ul>
<p><strong>说明</strong>：全局场景分类为分割的类别分布提供线索，因此很重要。金字塔池化模块（Pyramid pooling module）通过应用较大核池化层的获取这些信息。如上文中空洞卷积论文中所述，PSPNet 也使用空洞卷积改善 ResNet，并添加一个金字塔池化模块。该模块将 ResNet 的特征图与并行池化层的上采样输出结果连接起来，其中卷积核核覆盖了图像的全部、一半和小块区域。<br>在 ResNet 的第四阶段之后（即输入到金字塔池化模块），在主分支损失之外又增加了附加损失。这个想法在其他研究中也被称为中间监督（intermediate supervision）。<br><img src="/2018/07/08/图像语义分割综述/1531051779512.png" alt="PSPNet"></p>
<h3 id="Large-Kernel-Matters-（2017）"><a href="#Large-Kernel-Matters-（2017）" class="headerlink" title="Large Kernel Matters （2017）"></a>Large Kernel Matters （2017）</h3><p><strong>特点</strong>：提出了使用大卷积核的编码-译码架构<br><strong>说明</strong>：语义分割不仅需要分割，同时还需要对分割目标进行分类。由于分割结构中无法使用全连接层，因此带有大核函数的卷积可以替代全连接层得到应用。<br>使用大型核的另一个原因是，尽管 ResNet 等更深层的网络拥有较大的感受野，但相关研究显示这样的网络更易收集较小范围（即有效感受野）内的信息。大型核的计算成本高昂，且拥有大量参数。因此，$k  ×  k$卷积可近似成$ 1 × k + k × 1$、$k × 1$ 和 $1 × k$。这篇论文中将该模块称为全局卷积网络（GCN）。<br>再来看结构，ResNet（没有空洞卷积）构成该结构的编码器部分，而 GCN 和反卷积构成了解码器部分。该结构还使用了名为边界细化（Boundary Refinement ）的残差模块。<br><img src="/2018/07/08/图像语义分割综述/1531052099645.png" alt="Large Kernel Matters"></p>
<h3 id="DeepLab-v3-2017"><a href="#DeepLab-v3-2017" class="headerlink" title="DeepLab v3 (2017)"></a>DeepLab v3 (2017)</h3><p><strong>特点</strong>:</p>
<ul>
<li>提出了更通用的框架，适用于任何网络</li>
<li>复制了ResNet最后的block，并级联起来</li>
<li>在ASPP中使用BN层</li>
<li>没有使用CRF</li>
</ul>
<p><strong>说明</strong>：<br>与 DeepLabv2 和空洞卷积论文一样，该研究也使用空洞/扩张卷积来改进 ResNet 模型。改进后的 ASPP 包括图像层级特征连接、一个 1x1 的卷积和三个 3x3 的不同比率空洞卷积。每一个并行卷积层之后使用批量归一化操作。<br>级联模型是一个 ResNet 模块，但其中的卷积层是不同比率的空洞卷积。该模型与空洞卷积论文中的背景模块相似，但是它直接应用于中间特征图，而不是可信度地图（信念图是通道数与类别数相同的最终 CNN 特征图）。<br>该论文分别评估了这两个已提出的模型。两个模型在 验证集上的性能相似，带有 ASPP 的模型性能稍好，且未使用 CRF。这两个模型优于 DeepLabv2 中最优的模型。论文作者还提到性能的改进来自于批量归一化操作和更好的多尺度背景编码方式。<br><img src="/2018/07/08/图像语义分割综述/1531052303920.png" alt="DeepLab v3"></p>
<h3 id="FRRN-2017"><a href="#FRRN-2017" class="headerlink" title="FRRN(2017)"></a>FRRN(2017)</h3><p>Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes<br>语义分割广泛应用于多个领域，现阶段先进的语义分割模型大多依赖于预训练的网络，这些网络有着出色的识别性能(即语义特征丰富)，但缺乏定位精度。为了缓解这个问题，论文提出了一个新颖的类似于ResNet的网络架构，使用两条处理流将多尺度上下文信息和像素级精度结合起来：<br>一条流以全分辨率携带信息，用于实现精准的分割边界,另一条流经过一连串的池化操作获取high-level的feature用于识别。<br>两条流使用全分辨率残差单元(FRRU)相结合，最后得到预测结果上采样到指定大小。</p>
<h2 id="2-语义分割与目标检测关系"><a href="#2-语义分割与目标检测关系" class="headerlink" title="2 语义分割与目标检测关系"></a>2 语义分割与目标检测关系</h2><p><img src="/2018/07/08/图像语义分割综述/1530779278021.png" alt="图片来自知乎"></p>
<p>目标检测更一般化，其图像中出现的目标种类和数目都不定。语义分割是目标检测更进阶的任务，目标检测只需要框出每个目标的包围盒，语义分割需要进一步判断图像中哪些像素属于哪个目标。但是，语义分割不区分属于相同类别的不同实例。</p>
<p>目标检测相关论文：<br>Mask R-CNN<br>Perceptual GAN</p>
<h2 id="3-通向外星的链接"><a href="#3-通向外星的链接" class="headerlink" title="3 通向外星的链接"></a>3 通向外星的链接</h2><ul>
<li>DeepLab(1,2,3)系列总结的挺好的一篇博客：<a href="https://blog.csdn.net/u011974639/article/details/79148719" target="_blank" rel="noopener">https://blog.csdn.net/u011974639/article/details/79148719</a></li>
<li>CNN for Semantic Segmentation（语义分割，论文，代码，数据集，标注工具，blog）<strong>(绝佳好博客)</strong>：<a href="https://blog.csdn.net/fabulousli/article/details/78633531" target="_blank" rel="noopener">https://blog.csdn.net/fabulousli/article/details/78633531</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/08/图像语义分割综述/" data-id="cjjjf8q480004u8uqd9lghhwe" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deep-learning/">deep learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/semantic-segmentation/">semantic segmentation</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello-hexo" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/07/hello-hexo/" class="article-date">
  <time datetime="2018-07-07T02:27:44.000Z" itemprop="datePublished">2018-07-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/07/hello-hexo/">hello_hexo!</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>This is my first hexo blog!</p>
<p>Welcome！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/07/hello-hexo/" data-id="cjjjf8q2t0002u8uqhm9pmzte" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hexo tutorial" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/07/Hexo tutorial/" class="article-date">
  <time datetime="2018-07-07T02:05:16.054Z" itemprop="datePublished">2018-07-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/07/Hexo tutorial/">Hexo tutorial</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/07/Hexo tutorial/" data-id="cjjjf8q0b0000u8uqxx1148bk" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CV/">CV</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe/">caffe</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learning/">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/semantic-segmentation/">semantic segmentation</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/caffe/" style="font-size: 10px;">caffe</a> <a href="/tags/deep-learning/" style="font-size: 20px;">deep learning</a> <a href="/tags/semantic-segmentation/" style="font-size: 10px;">semantic segmentation</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/07/13/caffe-train-val-prototxt-solver-prototxt-deploy-prototxt/">caffe:train_val.prototxt,solver.prototxt,deploy.prototxt</a>
          </li>
        
          <li>
            <a href="/2018/07/08/图像语义分割综述/">图像语义分割综述</a>
          </li>
        
          <li>
            <a href="/2018/07/07/hello-hexo/">hello_hexo!</a>
          </li>
        
          <li>
            <a href="/2018/07/07/Hexo tutorial/">Hexo tutorial</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>